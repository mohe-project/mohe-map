{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -q git+https://github.com/google-research/vision_transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import jax\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from vit_jax import models\n",
    "\n",
    "import requests\n",
    "from io import BytesIO\n",
    "from PIL import Image\n",
    "from pprint import pprint # for neatly formatting print outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize model (currently available models: LiT-B16B, LiT-B16B_2, LiT-L16L, LiT-L16S, LiT-L16Ti)\n",
    "model_name = 'LiT-L16Ti'\n",
    "\n",
    "lit_model = models.get_model(model_name)\n",
    "tokenizer = lit_model.get_tokenizer()\n",
    "image_preprocessing = lit_model.get_image_preprocessing()\n",
    "lit_variables = lit_model.load_variables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that returns the top k results from similarity search (using Pinecone's cosine similarity)\n",
    "def image_embedding(url):\n",
    "  response = requests.get(url, stream=True)\n",
    "  image = Image.open(BytesIO(response.content))\n",
    "\n",
    "  if image.mode == 'RGBA':\n",
    "      image = image.convert('RGB')\n",
    "\n",
    "  image = image.resize((500, 500))\n",
    "  image = np.array(image)\n",
    "  preprocessed_images = image_preprocessing([image])\n",
    "\n",
    "  image_features, _, _ = lit_model.apply(lit_variables, images=preprocessed_images)\n",
    "  # print(image_features.tolist()[0])\n",
    "\n",
    "  return image_features.tolist()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_embeddings(texts):\n",
    "    query_tokens = tokenizer(texts)\n",
    "    _, query_features, _ = lit_model.apply(lit_variables, tokens=query_tokens)\n",
    "    # for vector in query_features:\n",
    "    #     print(vector)\n",
    "    \n",
    "    return query_features.tolist()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
